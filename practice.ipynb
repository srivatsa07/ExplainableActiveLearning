{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e59dae90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== HARDWARE INFORMATION =====\n",
      "System: Linux\n",
      "Hostname: fd97cee3f414\n",
      "OS Version: 5.15.0-134-generic #145-Ubuntu SMP Wed Feb 12 20:08:39 UTC 2025\n",
      "Architecture: x86_64\n",
      "Processor: x86_64\n",
      "CPU Model: Intel(R) Xeon(R) Gold 6330 CPU @ 2.00GHz\n",
      "CPU Cores: 112\n",
      "Total Memory: 257358 MB\n",
      "GPU: Unknown\n",
      "\n",
      "Disk Information:\n",
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         2.2T  716G  1.4T  35% /\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: lspci: not found\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "def get_hardware_info():\n",
    "    \"\"\"Gather information about the system hardware\"\"\"\n",
    "    hardware_info = {}\n",
    "    \n",
    "    # Basic system information\n",
    "    hardware_info[\"system\"] = platform.system()\n",
    "    hardware_info[\"node\"] = platform.node()\n",
    "    hardware_info[\"release\"] = platform.release()\n",
    "    hardware_info[\"version\"] = platform.version()\n",
    "    hardware_info[\"machine\"] = platform.machine()\n",
    "    hardware_info[\"processor\"] = platform.processor()\n",
    "    \n",
    "    # CPU information\n",
    "    if hardware_info[\"system\"] == \"Linux\":\n",
    "        try:\n",
    "            with open(\"/proc/cpuinfo\", \"r\") as f:\n",
    "                cpuinfo = f.read()\n",
    "            \n",
    "            # Extract CPU model\n",
    "            model_name = re.search(r\"model name\\s+:\\s+(.*)\", cpuinfo)\n",
    "            if model_name:\n",
    "                hardware_info[\"cpu_model\"] = model_name.group(1)\n",
    "            \n",
    "            # Count CPU cores\n",
    "            cores = len(re.findall(r\"processor\\s+:\", cpuinfo))\n",
    "            hardware_info[\"cpu_cores\"] = cores\n",
    "        except:\n",
    "            hardware_info[\"cpu_model\"] = \"Unknown\"\n",
    "            hardware_info[\"cpu_cores\"] = \"Unknown\"\n",
    "    \n",
    "    elif hardware_info[\"system\"] == \"Darwin\":  # macOS\n",
    "        try:\n",
    "            cpu_model = subprocess.check_output([\"sysctl\", \"-n\", \"machdep.cpu.brand_string\"]).decode().strip()\n",
    "            hardware_info[\"cpu_model\"] = cpu_model\n",
    "            \n",
    "            cpu_cores = subprocess.check_output([\"sysctl\", \"-n\", \"hw.physicalcpu\"]).decode().strip()\n",
    "            hardware_info[\"cpu_cores\"] = cpu_cores\n",
    "        except:\n",
    "            hardware_info[\"cpu_model\"] = \"Unknown\"\n",
    "            hardware_info[\"cpu_cores\"] = \"Unknown\"\n",
    "    \n",
    "    elif hardware_info[\"system\"] == \"Windows\":\n",
    "        try:\n",
    "            cpu_model = subprocess.check_output(\"wmic cpu get name\", shell=True).decode().strip().split('\\n')[1]\n",
    "            hardware_info[\"cpu_model\"] = cpu_model\n",
    "            \n",
    "            cpu_cores = subprocess.check_output(\"wmic cpu get NumberOfCores\", shell=True).decode().strip().split('\\n')[1]\n",
    "            hardware_info[\"cpu_cores\"] = cpu_cores\n",
    "        except:\n",
    "            hardware_info[\"cpu_model\"] = \"Unknown\"\n",
    "            hardware_info[\"cpu_cores\"] = \"Unknown\"\n",
    "    \n",
    "    # Memory information\n",
    "    if hardware_info[\"system\"] == \"Linux\":\n",
    "        try:\n",
    "            with open(\"/proc/meminfo\", \"r\") as f:\n",
    "                meminfo = f.read()\n",
    "            \n",
    "            total_memory = re.search(r\"MemTotal:\\s+(\\d+)\", meminfo)\n",
    "            if total_memory:\n",
    "                hardware_info[\"total_memory\"] = f\"{int(total_memory.group(1)) // 1024} MB\"\n",
    "        except:\n",
    "            hardware_info[\"total_memory\"] = \"Unknown\"\n",
    "    \n",
    "    elif hardware_info[\"system\"] == \"Darwin\":  # macOS\n",
    "        try:\n",
    "            total_memory = subprocess.check_output([\"sysctl\", \"-n\", \"hw.memsize\"]).decode().strip()\n",
    "            hardware_info[\"total_memory\"] = f\"{int(total_memory) // (1024 * 1024)} MB\"\n",
    "        except:\n",
    "            hardware_info[\"total_memory\"] = \"Unknown\"\n",
    "    \n",
    "    elif hardware_info[\"system\"] == \"Windows\":\n",
    "        try:\n",
    "            total_memory = subprocess.check_output(\"wmic ComputerSystem get TotalPhysicalMemory\", shell=True).decode().strip().split('\\n')[1]\n",
    "            hardware_info[\"total_memory\"] = f\"{int(total_memory) // (1024 * 1024)} MB\"\n",
    "        except:\n",
    "            hardware_info[\"total_memory\"] = \"Unknown\"\n",
    "    \n",
    "    # GPU information\n",
    "    if hardware_info[\"system\"] == \"Linux\":\n",
    "        try:\n",
    "            gpu_info = subprocess.check_output(\"lspci | grep -i 'vga\\\\|3d\\\\|2d'\", shell=True).decode()\n",
    "            if gpu_info:\n",
    "                hardware_info[\"gpu\"] = gpu_info.strip()\n",
    "            else:\n",
    "                hardware_info[\"gpu\"] = \"No GPU detected\"\n",
    "        except:\n",
    "            hardware_info[\"gpu\"] = \"Unknown\"\n",
    "    \n",
    "    elif hardware_info[\"system\"] == \"Darwin\":  # macOS\n",
    "        try:\n",
    "            gpu_info = subprocess.check_output(\"system_profiler SPDisplaysDataType | grep Chipset\", shell=True).decode()\n",
    "            if gpu_info:\n",
    "                hardware_info[\"gpu\"] = gpu_info.strip()\n",
    "            else:\n",
    "                hardware_info[\"gpu\"] = \"No GPU detected\"\n",
    "        except:\n",
    "            hardware_info[\"gpu\"] = \"Unknown\"\n",
    "    \n",
    "    elif hardware_info[\"system\"] == \"Windows\":\n",
    "        try:\n",
    "            gpu_info = subprocess.check_output(\"wmic path win32_VideoController get name\", shell=True).decode()\n",
    "            if gpu_info:\n",
    "                hardware_info[\"gpu\"] = gpu_info.split('\\n')[1].strip()\n",
    "            else:\n",
    "                hardware_info[\"gpu\"] = \"No GPU detected\"\n",
    "        except:\n",
    "            hardware_info[\"gpu\"] = \"Unknown\"\n",
    "    \n",
    "    # Disk information\n",
    "    if hardware_info[\"system\"] == \"Linux\":\n",
    "        try:\n",
    "            disk_info = subprocess.check_output(\"df -h /\", shell=True).decode()\n",
    "            hardware_info[\"disk\"] = disk_info.strip()\n",
    "        except:\n",
    "            hardware_info[\"disk\"] = \"Unknown\"\n",
    "    \n",
    "    elif hardware_info[\"system\"] == \"Darwin\" or hardware_info[\"system\"] == \"Windows\":\n",
    "        try:\n",
    "            disk_info = subprocess.check_output(\"df -h /\", shell=True).decode()\n",
    "            hardware_info[\"disk\"] = disk_info.strip()\n",
    "        except:\n",
    "            try:\n",
    "                # Alternative for Windows\n",
    "                disk_info = subprocess.check_output(\"wmic logicaldisk get deviceid, size, freespace\", shell=True).decode()\n",
    "                hardware_info[\"disk\"] = disk_info.strip()\n",
    "            except:\n",
    "                hardware_info[\"disk\"] = \"Unknown\"\n",
    "    \n",
    "    return hardware_info\n",
    "\n",
    "def print_hardware_info():\n",
    "    \"\"\"Print the hardware information in a readable format\"\"\"\n",
    "    info = get_hardware_info()\n",
    "    \n",
    "    print(\"\\n===== HARDWARE INFORMATION =====\")\n",
    "    print(f\"System: {info.get('system', 'Unknown')}\")\n",
    "    print(f\"Hostname: {info.get('node', 'Unknown')}\")\n",
    "    print(f\"OS Version: {info.get('release', 'Unknown')} {info.get('version', 'Unknown')}\")\n",
    "    print(f\"Architecture: {info.get('machine', 'Unknown')}\")\n",
    "    print(f\"Processor: {info.get('processor', 'Unknown')}\")\n",
    "    print(f\"CPU Model: {info.get('cpu_model', 'Unknown')}\")\n",
    "    print(f\"CPU Cores: {info.get('cpu_cores', 'Unknown')}\")\n",
    "    print(f\"Total Memory: {info.get('total_memory', 'Unknown')}\")\n",
    "    print(f\"GPU: {info.get('gpu', 'Unknown')}\")\n",
    "    print(\"\\nDisk Information:\")\n",
    "    print(info.get('disk', 'Unknown'))\n",
    "    print(\"===============================\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print_hardware_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99593fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs:\n",
      " - GPU 0: NVIDIA A10\n",
      " - GPU 1: NVIDIA A10\n"
     ]
    }
   ],
   "source": [
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\" - GPU {i}: {torch.cuda.get_device_name(i)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb43bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"hi\")\n",
    "device = torch.device( \"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print ( device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bc9de61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 14 18:31:26 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.06              Driver Version: 555.42.06      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A10                     Off |   00000000:17:00.0 Off |                    0 |\n",
      "|  0%   30C    P8             16W /  150W |       4MiB /  23028MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A10                     Off |   00000000:CA:00.0 Off |                    0 |\n",
      "|  0%   30C    P8             15W /  150W |       4MiB /  23028MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e85c0508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 2, 'NVIDIA A10')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available(), torch.cuda.device_count(), torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a62c1e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESOURCE MONITOR - Starting at 2025-04-14 18:31:32\n",
      "Monitoring for 10 seconds with 2 second intervals\n",
      "============================================================\n",
      "\n",
      "[2025-04-14 18:31:32] - Iteration 1/5\n",
      "\n",
      "CPU MEMORY:\n",
      "  Total: 251.33 GB\n",
      "  Used: 8.78 GB (4.2%)\n",
      "  Available: 240.71 GB\n",
      "\n",
      "GPU MEMORY:\n",
      "  GPU 1:\n",
      "    Name: NVIDIA A10\n",
      "    Total Memory: 22.49 GB\n",
      "    Used Memory: 0.00 GB\n",
      "    Free Memory: 22.09 GB\n",
      "    Usage: 0.0%\n",
      "  GPU 2:\n",
      "    Name: NVIDIA A10\n",
      "    Total Memory: 22.49 GB\n",
      "    Used Memory: 0.00 GB\n",
      "    Free Memory: 22.09 GB\n",
      "    Usage: 0.0%\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "[2025-04-14 18:31:34] - Iteration 2/5\n",
      "\n",
      "CPU MEMORY:\n",
      "  Total: 251.33 GB\n",
      "  Used: 8.78 GB (4.2%)\n",
      "  Available: 240.71 GB\n",
      "\n",
      "GPU MEMORY:\n",
      "  GPU 1:\n",
      "    Name: NVIDIA A10\n",
      "    Total Memory: 22.49 GB\n",
      "    Used Memory: 0.00 GB\n",
      "    Free Memory: 22.09 GB\n",
      "    Usage: 0.0%\n",
      "  GPU 2:\n",
      "    Name: NVIDIA A10\n",
      "    Total Memory: 22.49 GB\n",
      "    Used Memory: 0.00 GB\n",
      "    Free Memory: 22.09 GB\n",
      "    Usage: 0.0%\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "[2025-04-14 18:31:37] - Iteration 3/5\n",
      "\n",
      "CPU MEMORY:\n",
      "  Total: 251.33 GB\n",
      "  Used: 8.78 GB (4.2%)\n",
      "  Available: 240.71 GB\n",
      "\n",
      "GPU MEMORY:\n",
      "  GPU 1:\n",
      "    Name: NVIDIA A10\n",
      "    Total Memory: 22.49 GB\n",
      "    Used Memory: 0.00 GB\n",
      "    Free Memory: 22.09 GB\n",
      "    Usage: 0.0%\n",
      "  GPU 2:\n",
      "    Name: NVIDIA A10\n",
      "    Total Memory: 22.49 GB\n",
      "    Used Memory: 0.00 GB\n",
      "    Free Memory: 22.09 GB\n",
      "    Usage: 0.0%\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "[2025-04-14 18:31:39] - Iteration 4/5\n",
      "\n",
      "CPU MEMORY:\n",
      "  Total: 251.33 GB\n",
      "  Used: 8.78 GB (4.2%)\n",
      "  Available: 240.71 GB\n",
      "\n",
      "GPU MEMORY:\n",
      "  GPU 1:\n",
      "    Name: NVIDIA A10\n",
      "    Total Memory: 22.49 GB\n",
      "    Used Memory: 0.00 GB\n",
      "    Free Memory: 22.09 GB\n",
      "    Usage: 0.0%\n",
      "  GPU 2:\n",
      "    Name: NVIDIA A10\n",
      "    Total Memory: 22.49 GB\n",
      "    Used Memory: 0.00 GB\n",
      "    Free Memory: 22.09 GB\n",
      "    Usage: 0.0%\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "[2025-04-14 18:31:41] - Iteration 5/5\n",
      "\n",
      "CPU MEMORY:\n",
      "  Total: 251.33 GB\n",
      "  Used: 8.78 GB (4.2%)\n",
      "  Available: 240.71 GB\n",
      "\n",
      "GPU MEMORY:\n",
      "  GPU 1:\n",
      "    Name: NVIDIA A10\n",
      "    Total Memory: 22.49 GB\n",
      "    Used Memory: 0.00 GB\n",
      "    Free Memory: 22.09 GB\n",
      "    Usage: 0.0%\n",
      "  GPU 2:\n",
      "    Name: NVIDIA A10\n",
      "    Total Memory: 22.49 GB\n",
      "    Used Memory: 0.00 GB\n",
      "    Free Memory: 22.09 GB\n",
      "    Usage: 0.0%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import platform\n",
    "import subprocess\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def get_cpu_memory_gb():\n",
    "    \"\"\"Get CPU memory information in GB\"\"\"\n",
    "    # Get virtual memory statistics\n",
    "    memory = psutil.virtual_memory()\n",
    "    \n",
    "    # Calculate values in GB (1 GB = 1024^3 bytes)\n",
    "    total_memory_gb = memory.total / (1024 ** 3)\n",
    "    used_memory_gb = memory.used / (1024 ** 3)\n",
    "    available_memory_gb = memory.available / (1024 ** 3)\n",
    "    \n",
    "    return {\n",
    "        \"total_gb\": round(total_memory_gb, 2),\n",
    "        \"used_gb\": round(used_memory_gb, 2),\n",
    "        \"available_gb\": round(available_memory_gb, 2),\n",
    "        \"percent_used\": memory.percent\n",
    "    }\n",
    "\n",
    "def get_gpu_memory_info_gb():\n",
    "    \"\"\"Get GPU memory information in GB based on the platform\"\"\"\n",
    "    system = platform.system()\n",
    "    gpu_info = []\n",
    "    \n",
    "    if system == \"Windows\":\n",
    "        try:\n",
    "            # For NVIDIA GPUs on Windows\n",
    "            nvidia_smi_output = subprocess.check_output(\n",
    "                ['nvidia-smi', '--query-gpu=name,memory.total,memory.used,memory.free', '--format=csv,noheader,nounits'],\n",
    "                universal_newlines=True\n",
    "            )\n",
    "            \n",
    "            for line in nvidia_smi_output.strip().split('\\n'):\n",
    "                name, total, used, free = [item.strip() for item in line.split(',')]\n",
    "                gpu_info.append({\n",
    "                    \"name\": name,\n",
    "                    \"total_gb\": round(float(total) / 1024, 2),  # Convert from MB to GB\n",
    "                    \"used_gb\": round(float(used) / 1024, 2),\n",
    "                    \"free_gb\": round(float(free) / 1024, 2)\n",
    "                })\n",
    "                \n",
    "        except (subprocess.SubprocessError, FileNotFoundError):\n",
    "            gpu_info.append({\"error\": \"NVIDIA tools not available or no NVIDIA GPU found\"})\n",
    "            \n",
    "    elif system == \"Linux\":\n",
    "        try:\n",
    "            # For NVIDIA GPUs on Linux\n",
    "            nvidia_smi_output = subprocess.check_output(\n",
    "                ['nvidia-smi', '--query-gpu=name,memory.total,memory.used,memory.free', '--format=csv,noheader,nounits'],\n",
    "                universal_newlines=True\n",
    "            )\n",
    "            \n",
    "            for line in nvidia_smi_output.strip().split('\\n'):\n",
    "                name, total, used, free = [item.strip() for item in line.split(',')]\n",
    "                gpu_info.append({\n",
    "                    \"name\": name,\n",
    "                    \"total_gb\": round(float(total) / 1024, 2),  # Convert from MB to GB\n",
    "                    \"used_gb\": round(float(used) / 1024, 2),\n",
    "                    \"free_gb\": round(float(free) / 1024, 2)\n",
    "                })\n",
    "                \n",
    "        except (subprocess.SubprocessError, FileNotFoundError):\n",
    "            # Try AMD GPUs on Linux\n",
    "            try:\n",
    "                rocm_smi_output = subprocess.check_output(['rocm-smi', '--showmeminfo', 'vram'], universal_newlines=True)\n",
    "                pattern = r\"GPU\\[(\\d+)\\].*?:\\s+(\\d+)\\s+(\\d+)\"\n",
    "                matches = re.findall(pattern, rocm_smi_output)\n",
    "                \n",
    "                for gpu_id, used, total in matches:\n",
    "                    gpu_info.append({\n",
    "                        \"name\": f\"AMD GPU {gpu_id}\",\n",
    "                        \"total_gb\": round(float(total) / (1024 ** 2), 2),  # Convert from KB to GB\n",
    "                        \"used_gb\": round(float(used) / (1024 ** 2), 2),\n",
    "                        \"free_gb\": round((float(total) - float(used)) / (1024 ** 2), 2)\n",
    "                    })\n",
    "                    \n",
    "            except (subprocess.SubprocessError, FileNotFoundError):\n",
    "                gpu_info.append({\"error\": \"No GPU tools available or no supported GPU found\"})\n",
    "                \n",
    "    elif system == \"Darwin\":  # macOS\n",
    "        try:\n",
    "            # This is a simplified approach for macOS - may not work on all systems\n",
    "            system_profiler = subprocess.check_output(['system_profiler', 'SPDisplaysDataType'], universal_newlines=True)\n",
    "            \n",
    "            # Extract GPU names\n",
    "            gpu_names = re.findall(r\"Chipset Model: (.+)\", system_profiler)\n",
    "            \n",
    "            # Extract VRAM if available\n",
    "            vram_matches = re.findall(r\"VRAM \\(Total\\): (\\d+) MB\", system_profiler)\n",
    "            \n",
    "            for i, name in enumerate(gpu_names):\n",
    "                gpu_data = {\"name\": name}\n",
    "                \n",
    "                if i < len(vram_matches):\n",
    "                    total_mb = int(vram_matches[i])\n",
    "                    gpu_data[\"total_gb\"] = round(total_mb / 1024, 2)\n",
    "                    gpu_data[\"note\"] = \"macOS doesn't provide detailed GPU memory usage information\"\n",
    "                else:\n",
    "                    gpu_data[\"note\"] = \"VRAM information not available\"\n",
    "                    \n",
    "                gpu_info.append(gpu_data)\n",
    "                \n",
    "        except (subprocess.SubprocessError, FileNotFoundError):\n",
    "            gpu_info.append({\"error\": \"Could not retrieve GPU information on macOS\"})\n",
    "    else:\n",
    "        gpu_info.append({\"error\": f\"Unsupported operating system: {system}\"})\n",
    "        \n",
    "    return gpu_info\n",
    "\n",
    "def monitor_resources(interval=1, duration=10):\n",
    "    \"\"\"Monitor CPU and GPU resources for a specified duration and interval\"\"\"\n",
    "    iterations = int(duration / interval)\n",
    "    \n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"RESOURCE MONITOR - Starting at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Monitoring for {duration} seconds with {interval} second intervals\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # Clear screen for better visibility in terminal (comment out if not desired)\n",
    "        # os.system('cls' if platform.system() == 'Windows' else 'clear')\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"\\n[{timestamp}] - Iteration {i+1}/{iterations}\")\n",
    "        \n",
    "        # Get CPU memory info\n",
    "        cpu_memory = get_cpu_memory_gb()\n",
    "        print(\"\\nCPU MEMORY:\")\n",
    "        print(f\"  Total: {cpu_memory['total_gb']:.2f} GB\")\n",
    "        print(f\"  Used: {cpu_memory['used_gb']:.2f} GB ({cpu_memory['percent_used']}%)\")\n",
    "        print(f\"  Available: {cpu_memory['available_gb']:.2f} GB\")\n",
    "        \n",
    "        # Get GPU memory info\n",
    "        gpu_memory_info = get_gpu_memory_info_gb()\n",
    "        print(\"\\nGPU MEMORY:\")\n",
    "        \n",
    "        if not gpu_memory_info:\n",
    "            print(\"  No GPU information available\")\n",
    "        else:\n",
    "            for idx, gpu in enumerate(gpu_memory_info):\n",
    "                print(f\"  GPU {idx+1}:\")\n",
    "                \n",
    "                if \"error\" in gpu:\n",
    "                    print(f\"    {gpu['error']}\")\n",
    "                elif \"note\" in gpu:\n",
    "                    print(f\"    Name: {gpu['name']}\")\n",
    "                    if \"total_gb\" in gpu:\n",
    "                        print(f\"    Total Memory: {gpu['total_gb']:.2f} GB\")\n",
    "                    print(f\"    Note: {gpu['note']}\")\n",
    "                else:\n",
    "                    print(f\"    Name: {gpu['name']}\")\n",
    "                    print(f\"    Total Memory: {gpu['total_gb']:.2f} GB\")\n",
    "                    print(f\"    Used Memory: {gpu['used_gb']:.2f} GB\")\n",
    "                    print(f\"    Free Memory: {gpu['free_gb']:.2f} GB\")\n",
    "                    usage_percent = (gpu['used_gb'] / gpu['total_gb']) * 100\n",
    "                    print(f\"    Usage: {usage_percent:.1f}%\")\n",
    "        \n",
    "        print(f\"\\n{'-' * 60}\")\n",
    "        \n",
    "        # Wait for the next iteration, unless it's the last one\n",
    "        if i < iterations - 1:\n",
    "            time.sleep(interval)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # You can customize the monitoring duration and interval\n",
    "    monitor_resources(interval=2, duration=10)  # Check every 2 seconds for 10 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (thesis)",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
